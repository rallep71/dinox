/**
 * Security Audit Test Suite
 *
 * These tests are designed to FAIL against the current codebase because
 * they test what SHOULD happen according to the relevant specifications,
 * exposing real bugs found during manual code audit.
 *
 * See companion document: tests/SECURITY_AUDIT_FINDINGS.md
 */

// ============================================================================
// TEST GROUP 1: FileEncryption — NIST SP 800-38D & NIST SP 800-132 violations
// ============================================================================

/**
 * BUG 1.1: Key derivation uses single SHA-256 instead of PBKDF2/Argon2
 *
 * File: libdino/src/security/file_encryption.vala, derive_key() (lines 23-31)
 *
 * Actual code:
 *   Checksum checksum = new Checksum(ChecksumType.SHA256);
 *   checksum.update(password.data, password.length);
 *   checksum.update(SALT.data, SALT.length);
 *   → returns single SHA-256(password || salt)
 *
 * Spec (NIST SP 800-132 §5.1): Password-based key derivation MUST use
 * an approved KDF (PBKDF2) with an iteration count of at least 1000
 * (recommended: 600,000+ for SHA-256 per OWASP 2023).
 *
 * Impact: Single SHA-256 is brute-forceable at ~10 billion hashes/sec on
 * modern GPUs. A 6-character password falls in seconds.
 */
void test_file_encryption_key_derivation_uses_pbkdf2() {
    // Two different passwords should produce keys that take measurable time
    // to derive (indicating iteration), and the same password with different
    // salts should produce different keys.

    // SPEC EXPECTATION: derive_key should use PBKDF2 with ≥10,000 iterations.
    // ACTUAL: Uses single SHA-256, so derivation is instantaneous and there's
    //         no iteration count parameter.

    var enc1 = new Dino.Security.FileEncryption("password123");
    var enc2 = new Dino.Security.FileEncryption("password123");

    // With a proper KDF using random salts, encrypting the same plaintext
    // with two instances created from the same password would produce
    // different ciphertexts (because the salt should be random per instance).
    uint8[] plaintext = "test data".data;
    uint8[] ct1 = enc1.encrypt_data(plaintext);
    uint8[] ct2 = enc2.encrypt_data(plaintext);

    // The IVs are random so ciphertexts differ, but the KEYS are identical
    // because the salt is hardcoded. We can verify this by cross-decryption:
    // If keys were derived with random salts, cross-decryption would FAIL.
    try {
        uint8[] pt_cross = enc2.decrypt_data(ct1);
        // THIS SHOULD FAIL per spec (random salt per derivation),
        // but it SUCCEEDS because salt is hardcoded "DinoX File Encryption v1"
        assert_not_reached(); // EXPECTED: cross-decryption fails
    } catch (Error e) {
        // SPEC-CORRECT: Different random salts → different keys → decryption fails
    }
}


/**
 * BUG 1.2: Hardcoded constant salt
 *
 * File: libdino/src/security/file_encryption.vala, line 19
 *   private const string SALT = "DinoX File Encryption v1";
 *
 * Spec (NIST SP 800-132 §5.1): The salt SHALL be a random value of at
 * least 128 bits, generated by an approved random bit generator. The salt
 * shall be stored/transmitted alongside the derived key material.
 *
 * Impact: All users share the same salt. Pre-computed rainbow tables
 * for this specific salt can crack all passwords simultaneously.
 */
void test_file_encryption_salt_is_random_per_operation() {
    // Encrypt same plaintext twice with same password.
    // With random salt, the encrypted output (ignoring IV) would have
    // different key material → entirely different ciphertext structure.
    // The salt should be prepended to the output.

    var enc = new Dino.Security.FileEncryption("testpass");
    uint8[] plaintext = "hello world".data;

    uint8[] ct1 = enc.encrypt_data(plaintext);
    uint8[] ct2 = enc.encrypt_data(plaintext);

    // Skip IV (12 bytes) — compare the derived key effect.
    // With static salt, the key is the same both times, so decryption
    // with either IV works. With random salt per encryption, you'd need
    // to store the salt in the output and use it for decryption.

    // The output format should be: SALT(16+) || IV(12) || CIPHERTEXT || TAG(16)
    // ACTUAL format: IV(12) || CIPHERTEXT || TAG(16) — no salt stored!
    // This means the salt is constant and not stored.
    int expected_min_size = 16 + 12 + plaintext.length + 16; // salt+iv+data+tag
    assert(ct1.length >= expected_min_size); // FAILS: output is only iv+data+tag
}


/**
 * BUG 1.3: decrypt_stream outputs plaintext BEFORE verifying GCM auth tag
 *
 * File: libdino/src/security/file_encryption.vala, decrypt_stream() lines 69-121
 *
 * Actual code:
 *   while (true) {
 *       ... cipher.decrypt(out_held, tag_buffer);
 *       yield output.write_all_async(out_held, ...);  // ← plaintext output!
 *       ...
 *   }
 *   cipher.check_tag(tag_buffer);  // ← tag checked AFTER all plaintext written
 *
 * Spec (NIST SP 800-38D §7.2): "If the tag is not valid, [the output]
 * is FAIL, and the plaintext and AAD should not be revealed."
 *
 * Impact: An attacker can modify ciphertext; the victim receives and
 * processes tampered plaintext before discovering the tag is invalid.
 * Classic "release of unverified plaintext" vulnerability.
 */
void test_file_encryption_no_plaintext_before_tag_check() {
    var enc = new Dino.Security.FileEncryption("testpass");
    uint8[] plaintext = new uint8[65536]; // 64KB of data
    for (int i = 0; i < plaintext.length; i++) plaintext[i] = (uint8)(i & 0xFF);

    uint8[] ciphertext = enc.encrypt_data(plaintext);

    // Tamper with the ciphertext body (NOT the tag) — flip a byte in the middle
    int tamper_pos = 12 + (ciphertext.length - 12 - 16) / 2; // middle of ciphertext
    ciphertext[tamper_pos] ^= 0xFF;

    // Create streams for streaming decryption
    var input_stream = new MemoryInputStream.from_data(ciphertext);
    var output_stream = new MemoryOutputStream.resizable();

    // SPEC EXPECTATION: decrypt_stream should NOT write ANY data to output
    // before tag verification. It should buffer internally and only release
    // plaintext after tag passes — or use an encrypt-then-MAC scheme.
    try {
        enc.decrypt_stream.begin(input_stream, output_stream, null, (obj, res) => {
            try {
                enc.decrypt_stream.end(res);
                assert_not_reached(); // Should throw due to bad tag
            } catch (Error e) {
                // Good: tag check failed.
            }
        });
    } catch (Error e) {
        // Expected
    }

    // BUG EXPOSURE: output_stream already contains unverified plaintext
    // because the code writes chunks before checking the tag at the end.
    // Per NIST SP 800-38D, output_stream should be EMPTY here.
    assert(output_stream.get_data_size() == 0);
    // THIS FAILS: output_stream contains the tampered-but-decrypted plaintext
}


// ============================================================================
// TEST GROUP 2: RateLimiter — Edge case bugs
// ============================================================================

/**
 * BUG 2.1: window_seconds=0 completely bypasses rate limiting
 *
 * File: plugins/bot-features/src/rate_limiter.vala, check() lines 20-36
 *
 * Actual code:
 *   if (now - w.window_start >= window_seconds) {  // 0: always true
 *       w.window_start = now;
 *       w.request_count = 0;  // ← counter reset EVERY call
 *   }
 *
 * When window_seconds=0, the condition `now - w.window_start >= 0` is
 * always true, so request_count is reset to 0 on every check() call,
 * making max_requests meaningless.
 *
 * Expected: window_seconds=0 should either be rejected in the constructor
 * or should mean "no window → all requests counted forever against max."
 */
void test_rate_limiter_zero_window_still_limits() {
    var limiter = new Dino.Plugins.BotFeatures.RateLimiter(5, 0); // max 5, 0s window

    // Make 10 requests — should be rate-limited after 5
    for (int i = 0; i < 5; i++) {
        assert(limiter.check(1) == true);  // First 5 should pass
    }
    assert(limiter.check(1) == false);
    // BUG: This FAILS because window_seconds=0 causes the window to reset
    // on every call, so every request is allowed regardless of max_requests.
}


/**
 * BUG 2.2: Clock going backwards permanently locks out a bot
 *
 * File: plugins/bot-features/src/rate_limiter.vala, check() lines 26-29
 *
 * If the system clock jumps backwards (NTP correction, DST, VM migration),
 * `now - w.window_start` becomes negative. This is always < window_seconds,
 * so the window NEVER resets. Once max_requests is hit, the bot is
 * permanently locked out until the clock catches up to the old window_start.
 *
 * Expected: Rate limiter should detect clock regression and reset the window.
 */
void test_rate_limiter_clock_backwards_doesnt_lock_out() {
    // This test requires injecting a clock, which the current code doesn't
    // support (it hard-codes DateTime.now_utc()). The test demonstrates
    // the design flaw.

    var limiter = new Dino.Plugins.BotFeatures.RateLimiter(2, 60);

    // Simulate: 2 requests exhaust the limit
    assert(limiter.check(1) == true);
    assert(limiter.check(1) == true);
    assert(limiter.check(1) == false); // Rate limited

    // BUG: If the clock now goes back 30 seconds, `now - window_start`
    // is negative (-30), which is < 60, so the window never resets.
    // The bot stays locked out for 60 + 30 = 90 seconds instead of 60.
    // In extreme cases (clock back by hours/days), lockout is indefinite.

    // SPEC EXPECTATION: The limiter should accept a TimeProvider interface
    // and handle `now < window_start` by resetting the window.
    // ACTUAL: Hard-coded DateTime.now_utc() with no backwards-clock handling.

    // We can at least verify the constructor rejects invalid parameters:
    // (This also fails — no validation exists)
    try {
        var bad_limiter = new Dino.Plugins.BotFeatures.RateLimiter(-1, -5);
        // Should throw/reject negative values
        assert_not_reached();
    } catch (Error e) {
        // Expected: invalid parameters rejected
    }
}


/**
 * BUG 2.3: Integer overflow in cleanup() — window_seconds * 10
 *
 * File: plugins/bot-features/src/rate_limiter.vala, cleanup() line 54
 *   if (now - entry.value.window_start > window_seconds * 10)
 *
 * `window_seconds` is `int` (32-bit signed). If window_seconds > 214748364,
 * then `window_seconds * 10` overflows, wrapping to a negative number.
 * This causes `now - window_start > (negative)` to almost always be true,
 * removing ALL windows including active ones.
 *
 * Expected: Use int64 arithmetic or validate window_seconds range.
 */
void test_rate_limiter_cleanup_large_window_no_overflow() {
    // window_seconds = 300_000_000 (~9.5 years, pathological but valid int)
    var limiter = new Dino.Plugins.BotFeatures.RateLimiter(100, 300000000);

    // Add a fresh window
    assert(limiter.check(42) == true);

    // Cleanup should NOT remove a window that was just created
    limiter.cleanup();

    // The window should still exist and have counted the request
    assert(limiter.check(42) == true); // Should be request #2, within limit

    // BUG: 300000000 * 10 = 3,000,000,000 overflows int (max 2,147,483,647)
    // The overflow produces a negative number, so the comparison
    // `now - 0 > (negative)` is true, and the window is incorrectly removed.
    // After cleanup, bot 42's window is gone, so this is effectively request #1
    // instead of #2. Rate limiting state is silently lost.
}


// ============================================================================
// TEST GROUP 3: TokenManager — Security violations
// ============================================================================

/**
 * BUG 3.1: Raw token stored in database alongside hash
 *
 * File: plugins/bot-features/src/token_manager.vala, generate_token() lines 15-21
 *
 * Actual code:
 *   string hash = hash_token(raw_token);
 *   registry.update_bot_token_hash(bot_id, hash);
 *   registry.update_bot_token_raw(bot_id, raw_token);  // ← STORES RAW TOKEN!
 *
 * The function comment says "The SHA-256 hash is stored in the database"
 * but the code ALSO stores the raw token via update_bot_token_raw().
 * This completely defeats the purpose of hashing — a database breach
 * exposes all tokens in plaintext.
 *
 * Expected: Only the hash should be stored. The raw token should be
 * returned to the user once and never persisted.
 */
void test_token_manager_does_not_store_raw_token() {
    // After generate_token(), the registry should NOT have the raw token.
    // Only the SHA-256 hash should be stored.

    // Mock registry that records what's stored
    var registry = new MockBotRegistry();
    var tm = new Dino.Plugins.BotFeatures.TokenManager(registry);

    string raw_token = tm.generate_token(1);

    // SPEC EXPECTATION: Only hash stored, raw token not persisted
    assert(registry.stored_token_raw == null || registry.stored_token_raw == "");
    // BUG: This FAILS because generate_token() calls
    //   registry.update_bot_token_raw(bot_id, raw_token)
    // storing the plaintext token in the database.

    // Verify hash IS stored
    assert(registry.stored_token_hash != null);
    assert(registry.stored_token_hash.length == 64); // SHA-256 hex = 64 chars
}


/**
 * BUG 3.2: hash_token uses plain SHA-256, not keyed HMAC
 *
 * File: plugins/bot-features/src/token_manager.vala, hash_token() lines 56-60
 *
 * Actual code:
 *   Checksum checksum = new Checksum(ChecksumType.SHA256);
 *   checksum.update((uchar[]) token.data, token.data.length);
 *   return checksum.get_string();
 *
 * This is plain SHA-256 without any server-side secret key. If the token
 * hash database is breached, an attacker can verify candidate tokens
 * offline using only the public SHA-256 algorithm. With HMAC using a
 * server-side key, the hashes are useless without the key.
 *
 * The code already has hmac_sha256() implemented (lines 68-79) but
 * doesn't use it for token hashing!
 *
 * Expected: hash_token should use HMAC-SHA256 with a server-side secret.
 */
void test_token_hash_uses_hmac_not_plain_sha256() {
    string token = "bot1:550e8400-e29b-41d4-a716-446655440000";

    // Plain SHA-256 of the token — predictable without any secret
    string plain_hash = Dino.Plugins.BotFeatures.TokenManager.hash_token(token);

    // Compute expected plain SHA-256 independently
    Checksum cs = new Checksum(ChecksumType.SHA256);
    cs.update((uchar[]) token.data, token.data.length);
    string expected_plain = cs.get_string();

    // BUG: hash_token produces the same output as plain SHA-256
    // It SHOULD use HMAC-SHA256 with a server-side key, so the output
    // would NOT match plain SHA-256.
    assert(plain_hash != expected_plain);
    // THIS FAILS: plain_hash == expected_plain because hash_token IS plain SHA-256
}


// ============================================================================
// TEST GROUP 4: AuthMiddleware — JSON injection
// ============================================================================

/**
 * BUG 4.1: Incomplete JSON escaping in send_error — backslashes not escaped
 *
 * File: plugins/bot-features/src/auth_middleware.vala, send_error() lines 52-55
 *
 * Actual code:
 *   string json = "{\"ok\":false,\"error\":\"%s\",\"description\":\"%s\"}".printf(
 *       error_code, description.replace("\"", "\\\"")
 *   );
 *
 * Only double-quotes are escaped. Backslashes are NOT escaped first.
 * If description contains `\"`, the replace turns it into `\\\"`:
 *   Input:  test\"end
 *   After:  test\\\"end
 *   JSON:   {"description":"test\\\"end"}
 *   Parsed: test\ followed by string terminator " → BROKEN JSON
 *
 * Also: `error_code` is NEVER escaped at all.
 *
 * Expected: Full JSON string escaping: escape \ first, then " and control chars.
 * Or better: use a proper JSON builder (Json.Builder).
 */
void test_auth_middleware_json_escaping_handles_backslashes() {
    // Create a mock Soup.ServerMessage
    var msg = new Soup.ServerMessage("GET", new Soup.URI("http://localhost/test"));

    // Description containing a backslash followed by a quote
    string dangerous_desc = "token contains \\\" characters";

    Dino.Plugins.BotFeatures.AuthMiddleware.send_error(
        msg, 400, "bad_request", dangerous_desc
    );

    // Get the response body
    var body = msg.get_response_body();
    string json_str = (string) body.data;

    // Try to parse the JSON — it should be valid
    var parser = new Json.Parser();
    try {
        parser.load_from_data(json_str);
        // If we get here, JSON is valid
        var root = parser.get_root().get_object();
        string desc = root.get_string_member("description");
        assert(desc == dangerous_desc); // Round-trip should preserve the value
    } catch (Error e) {
        // BUG EXPOSED: JSON parsing fails because backslashes aren't properly escaped
        assert_not_reached(); // We should never get invalid JSON from our own code
    }
}


/**
 * BUG 4.2: error_code parameter is never JSON-escaped
 *
 * File: plugins/bot-features/src/auth_middleware.vala, send_error() line 53
 *   "{\"ok\":false,\"error\":\"%s\",...}".printf(error_code, ...)
 *
 * error_code is interpolated directly into JSON without any escaping.
 * Currently all callers use safe hardcoded strings, but the API is unsafe.
 *
 * Expected: error_code should also be escaped, or send_error should use
 * a JSON builder that handles all escaping automatically.
 */
void test_auth_middleware_error_code_is_escaped() {
    var msg = new Soup.ServerMessage("GET", new Soup.URI("http://localhost/test"));

    // If someone passes an error_code with special chars, JSON breaks
    Dino.Plugins.BotFeatures.AuthMiddleware.send_error(
        msg, 400, "bad\"code", "test description"
    );

    var body = msg.get_response_body();
    string json_str = (string) body.data;

    var parser = new Json.Parser();
    try {
        parser.load_from_data(json_str);
        var root = parser.get_root().get_object();
        assert(root.get_string_member("error") == "bad\"code");
    } catch (Error e) {
        assert_not_reached(); // JSON should always be valid
    }
    // BUG: This FAILS because error_code is never escaped, producing:
    //   {"ok":false,"error":"bad"code","description":"test description"}
    //   which is invalid JSON
}


// ============================================================================
// TEST GROUP 5: StreamManagement (XEP-0198) — Counter bugs
// ============================================================================

/**
 * BUG 5.1: h counter uses signed int, overflows at 2^31 instead of 2^32
 *
 * File: xmpp-vala/src/module/xep/0198_stream_management.vala, lines 10-11
 *   public int h_inbound = 0;
 *   public int h_outbound = 0;
 *
 * XEP-0198 §5: "the counter for a given stream MUST NOT exceed the
 * number of stanzas handled during the lifetime of the stream" and
 * "the value of 'h' [...] is an unsigned integer" that "wraps around
 * from 2^32-1 back to zero (0)."
 *
 * Vala's `int` is 32-bit SIGNED (max 2,147,483,647). The spec requires
 * an unsigned 32-bit counter (max 4,294,967,295). The counter overflows
 * at half the specified range, and negative values are serialized
 * incorrectly (e.g., h="-1" instead of h="4294967295").
 *
 * Impact: After ~2 billion stanzas, the counter goes negative, breaking
 * ack handling and potentially losing messages.
 */
void test_stream_management_h_counter_handles_uint32_range() {
    var module = new Xmpp.Xep.StreamManagement.Module();

    // Simulate receiving 2^31 stanzas (just past int max)
    module.h_inbound = int.MAX; // 2,147,483,647
    // Receive one more stanza — on_stanza_received does h_inbound++
    module.h_inbound++;

    // XEP-0198 says this should be 2,147,483,648 (2^31)
    // But int overflow in Vala wraps to -2,147,483,648
    assert(module.h_inbound > 0); // FAILS: h_inbound is now negative

    // The serialized value should be "2147483648" not "-2147483648"
    string serialized = module.h_inbound.to_string();
    assert(!serialized.has_prefix("-")); // FAILS: serialized is "-2147483648"
}


/**
 * BUG 5.2: handle_ack() doesn't check for null h attribute
 *
 * File: xmpp-vala/src/module/xep/0198_stream_management.vala, lines 206-210
 *
 * Actual code:
 *   string? h_acked = node.get_attribute("h", NS_URI);
 *   int parsed_int = int.parse(h_acked);  // ← h_acked can be null!
 *
 * If a malformed <a/> element arrives without an "h" attribute,
 * `h_acked` is null and `int.parse(null)` crashes with a segfault
 * or produces undefined behavior.
 *
 * Expected: Validate that h_acked is non-null before parsing. Return
 * or log warning if the attribute is missing (defensive parsing).
 */
void test_stream_management_handle_ack_null_h() {
    var module = new Xmpp.Xep.StreamManagement.Module();

    // Create an <a/> element WITHOUT the required 'h' attribute
    var node = new Xmpp.StanzaNode.build("a", Xmpp.Xep.StreamManagement.NS_URI)
        .add_self_xmlns();
    // Deliberately omitting .put_attribute("h", ...)

    // This should NOT crash — it should be handled gracefully
    // BUG: int.parse(null) causes undefined behavior / segfault
    // module.handle_ack(stream, node); // Would crash
}


/**
 * BUG 5.3: handle_incoming_h doesn't handle wrap-around at 2^32
 *
 * File: xmpp-vala/src/module/xep/0198_stream_management.vala, lines 213-222
 *
 * Actual code:
 *   foreach (int nr in in_flight_stanzas.keys) {
 *       if (nr <= h) {
 *           remove_nrs.add(nr);
 *       }
 *   }
 *
 * XEP-0198 §5: the h counter wraps from 2^32-1 to 0. If h wraps,
 * stanzas with numbers near 2^32-1 (e.g., 4294967290) should be
 * considered acked when h becomes a small number (e.g., 5), because
 * 5 is "after" 4294967290 in the wrapping sequence.
 *
 * The simple `nr <= h` comparison doesn't handle this — when h wraps
 * to 0, ALL in-flight stanzas have nr > h, so NONE are acked. They
 * remain in the in_flight_stanzas map forever (memory leak) and are
 * never acknowledged.
 */
void test_stream_management_h_wraparound_acks_old_stanzas() {
    var module = new Xmpp.Xep.StreamManagement.Module();

    // Simulate: h_outbound is near max uint32, several stanzas in flight
    // After wrap-around, ack with small h should clear old stanzas.

    // This requires uint32 counters. With int, we can't even represent
    // values > 2^31-1. The test documents the design flaw.

    // With uint32:
    //   Stanza sent at h=4294967293 (2^32 - 3)
    //   Stanza sent at h=4294967294 (2^32 - 2)
    //   Stanza sent at h=4294967295 (2^32 - 1)
    //   Stanza sent at h=0           (wrapped)
    //   Stanza sent at h=1
    //   Server acks h=1 → all 5 stanzas should be cleared
    //
    // ACTUAL: nr <= h → only h=0 and h=1 are cleared.
    //   h=4294967293, 4294967294, 4294967295 remain forever.

    // Even with int, near INT_MAX:
    module.h_outbound = int.MAX - 2; // 2147483645
    // Can't add stanzas to in_flight_stanzas directly (private),
    // but the design flaw is clear: no modular arithmetic for wrap-around.
}


// ============================================================================
// TEST GROUP 6: MAM (XEP-0313) — query_id not bound to sender
// ============================================================================

/**
 * BUG 6.1: active_query_ids is a flat set — not bound to sender JID
 *
 * File: xmpp-vala/src/module/xep/0313_message_archive_management.vala
 *   Flag class (line 152): active_query_ids is Gee.Set<string>
 *   ReceivedPipelineListener (line 128): flag.active_query_ids.contains(query_id)
 *
 * The query_id set is global, not scoped per server/JID. When querying
 * multiple archives (own archive + MUC archives), a malicious MUC server
 * could inject results using a query_id that was intended for a different
 * archive, bypassing the from-JID validation.
 *
 * XEP-0313 §5.2: Results MUST only be accepted from the archive that
 * was queried. The implementation should track (query_id → target_jid)
 * mappings, not just a set of active query_ids.
 *
 * Expected: active_query_ids should be a Map<string, Jid> mapping each
 * query_id to the JID it was sent to, and the result sender should be
 * verified against that mapping.
 */
void test_mam_query_id_bound_to_server() {
    // Scenario:
    // 1. Client sends MAM query to own archive (user@server) with queryid="q1"
    // 2. Client sends MAM query to MUC (room@muc.server) with queryid="q2"
    // 3. Malicious MUC sends a <result> with queryid="q1" and from="room@muc.server"
    //
    // EXPECTED: Message rejected — q1 was sent to user@server, not room@muc.server
    // ACTUAL: Message accepted — active_query_ids.contains("q1") is true
    //         regardless of where the result came from

    // The from-check on line 136 does mitigate this partially:
    //   if (!message.from.equals(my_jid.bare_jid) && !message.from.equals_bare(inner_from))
    // But this check is separate from query_id tracking. A MUC server that
    // controls both from and inner_from can still inject messages for any
    // active query_id.
}


// ============================================================================
// TEST GROUP 7: KeyManager — Insecure PRNG for key generation
// ============================================================================

/**
 * BUG 7.1: generate_new_file_key uses GLib.Random instead of CSPRNG
 *
 * File: libdino/src/security/key_manager.vala, generate_new_file_key() lines 118-121
 *
 * Actual code:
 *   for (int i = 0; i < 32; i++) {
 *       key_bytes[i] = (uint8) Random.int_range(0, 256);
 *   }
 *
 * GLib.Random uses the Mersenne Twister PRNG, which is NOT cryptographically
 * secure. Its internal state can be recovered from 624 consecutive 32-bit
 * outputs, after which all past and future outputs are predictable.
 *
 * Compare with the CORRECT implementation in try_secrets_service() (line 97):
 *   var file = File.new_for_path("/dev/urandom");
 *   var input = file.read();
 *   input.read_all(key_bytes, out bytes_read);
 *
 * The Linux/secrets path uses /dev/urandom (CSPRNG) ✓
 * The file-based/Windows path uses GLib.Random (NOT CSPRNG) ✗
 *
 * Impact: On Windows (or Linux without keyring), the OMEMO database
 * encryption key is generated from a predictable PRNG. An attacker who
 * can observe or guess the PRNG state can derive the key.
 *
 * Expected: Use /dev/urandom, getrandom(2), or equivalent CSPRNG.
 */
void test_key_manager_uses_csprng_for_key_generation() {
    // Generate two keys in quick succession
    // With Mersenne Twister, the PRNG state is deterministic from seed.
    // With a CSPRNG, outputs are indistinguishable from random.

    // We can test that the implementation uses a proper CSPRNG by verifying
    // it does NOT use GLib.Random. Since we can't easily mock Random,
    // we test a statistical property: GLib.Random seeded with the same
    // value produces identical output.

    // Seed GLib.Random to a known state
    Random.set_seed(12345);
    uint8[] key1 = new uint8[32];
    for (int i = 0; i < 32; i++) {
        key1[i] = (uint8) Random.int_range(0, 256);
    }

    // Re-seed to same state
    Random.set_seed(12345);
    uint8[] key2 = new uint8[32];
    for (int i = 0; i < 32; i++) {
        key2[i] = (uint8) Random.int_range(0, 256);
    }

    // Mersenne Twister: key1 == key2 (deterministic from seed)
    bool identical = true;
    for (int i = 0; i < 32; i++) {
        if (key1[i] != key2[i]) { identical = false; break; }
    }
    assert(identical == true); // This PASSES, proving GLib.Random is deterministic

    // A CSPRNG-based generate_new_file_key() should use /dev/urandom or
    // equivalent, NOT GLib.Random. The bug is that it uses Random.int_range().
    // To properly test: generate_new_file_key should be refactored to use
    // the same /dev/urandom approach as try_secrets_service().
}


// ============================================================================
// Main — run all tests
// ============================================================================

int main(string[] args) {
    Test.init(ref args);

    Test.add_func("/security/file_encryption/key_derivation_uses_pbkdf2",
        test_file_encryption_key_derivation_uses_pbkdf2);
    Test.add_func("/security/file_encryption/salt_is_random",
        test_file_encryption_salt_is_random_per_operation);
    Test.add_func("/security/file_encryption/no_plaintext_before_tag",
        test_file_encryption_no_plaintext_before_tag_check);

    Test.add_func("/security/rate_limiter/zero_window_limits",
        test_rate_limiter_zero_window_still_limits);
    Test.add_func("/security/rate_limiter/clock_backwards",
        test_rate_limiter_clock_backwards_doesnt_lock_out);
    Test.add_func("/security/rate_limiter/cleanup_overflow",
        test_rate_limiter_cleanup_large_window_no_overflow);

    Test.add_func("/security/token_manager/no_raw_token_stored",
        test_token_manager_does_not_store_raw_token);
    Test.add_func("/security/token_manager/hash_uses_hmac",
        test_token_hash_uses_hmac_not_plain_sha256);

    Test.add_func("/security/auth_middleware/json_escaping_backslashes",
        test_auth_middleware_json_escaping_handles_backslashes);
    Test.add_func("/security/auth_middleware/error_code_escaped",
        test_auth_middleware_error_code_is_escaped);

    Test.add_func("/security/stream_management/h_counter_uint32",
        test_stream_management_h_counter_handles_uint32_range);
    Test.add_func("/security/stream_management/null_h_attribute",
        test_stream_management_handle_ack_null_h);
    Test.add_func("/security/stream_management/h_wraparound",
        test_stream_management_h_wraparound_acks_old_stanzas);

    Test.add_func("/security/mam/query_id_bound_to_server",
        test_mam_query_id_bound_to_server);

    Test.add_func("/security/key_manager/uses_csprng",
        test_key_manager_uses_csprng_for_key_generation);

    return Test.run();
}
